{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /home/fesih/Desktop/ubuntu_projects/GAST2\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Get current working directory\n",
    "cwd = Path(os.getcwd())\n",
    "# Set project root by going one level up\n",
    "PROJECT_ROOT = cwd.parents[1]  # Adjust this as necessary\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(gt_path, \"r\") as f:\n",
    "    print(\"\\nKeys in Houston13_7gt.mat:\", list(f.keys()))\n",
    "    # Let's assume the main data is under the first key\n",
    "    main_key = list(f.keys())[0]\n",
    "    cube = f[main_key][()]\n",
    "    print(f\"Cube shape: {cube.shape}\")\n",
    "    print(f\"Cube dtype: {cube.dtype}\")\n",
    "    print(\"Min value:\", np.min(cube))\n",
    "    print(\"Max value:\", np.max(cube))\n",
    "    print(\"Mean value:\", np.mean(cube))\n",
    "    print(\"Std value:\", np.std(cube))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in Houston13.mat: ['ori_data']\n",
      "Cube shape: (48, 954, 210)\n",
      "Cube dtype: float64\n",
      "Min value: 0.0\n",
      "Max value: 1.0\n",
      "Mean value: 0.08720015110251707\n",
      "Std value: 0.057268523853831174\n",
      "\n",
      "Keys in Houston13_7gt.mat: ['map']\n",
      "Cube shape: (954, 210)\n",
      "Cube dtype: float64\n",
      "Min value: 0.0\n",
      "Max value: 7.0\n",
      "Mean value: 0.05218129180393331\n",
      "Std value: 0.5166417734271238\n"
     ]
    }
   ],
   "source": [
    "# Path to the Houston13 .mat file\n",
    "mat_path = PROJECT_ROOT / \"src/Dataset/Houston13/Houston13.mat\"\n",
    "gt_path = PROJECT_ROOT / \"src/Dataset/Houston13/Houston13_7gt.mat\"\n",
    "\n",
    "import h5py\n",
    "# Load the .mat file\n",
    "\n",
    "with h5py.File(mat_path, \"r\") as f:\n",
    "    print(\"Keys in 2013_IEEE_GRSS_DF_Contest_CASI_349_1905_144.mat:\", list(f.keys()))\n",
    "    # Let's assume the main data is under the first key\n",
    "    main_key = list(f.keys())[0]\n",
    "    cube = f[main_key][()]\n",
    "    print(f\"Cube shape: {cube.shape}\")\n",
    "    print(f\"Cube dtype: {cube.dtype}\")\n",
    "    print(\"Min value:\", np.min(cube))\n",
    "    print(\"Max value:\", np.max(cube))\n",
    "    print(\"Mean value:\", np.mean(cube))\n",
    "    print(\"Std value:\", np.std(cube))\n",
    "\n",
    "with h5py.File(gt_path, \"r\") as f:\n",
    "    print(\"\\nKeys in Houston13_7gt.mat:\", list(f.keys()))\n",
    "    # Let's assume the main data is under the first key\n",
    "    main_key = list(f.keys())[0]\n",
    "    cube = f[main_key][()]\n",
    "    print(f\"Cube shape: {cube.shape}\")\n",
    "    print(f\"Cube dtype: {cube.dtype}\")\n",
    "    print(\"Min value:\", np.min(cube))\n",
    "    print(\"Max value:\", np.max(cube))\n",
    "    print(\"Mean value:\", np.mean(cube))\n",
    "    print(\"Std value:\", np.std(cube))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation: Loading Any Version of MATLAB `.mat` Files in Python\n",
    "\n",
    "This code provides a robust way to load MATLAB `.mat` files of **any version** (including v7.3 HDF5-based files) into Python using `scipy.io.loadmat`. It automatically converts v7.3 files to the older v7.2 format if needed.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "- **convert_mat_v73_to_v72(v73_path, v72_path):**\n",
    "  - Loads a v7.3 (HDF5) `.mat` file using `h5py`.\n",
    "  - Recursively extracts all datasets and groups into a Python dictionary.\n",
    "  - Saves the data as a v7.2 `.mat` file using `scipy.io.savemat`, which is compatible with `scipy.io.loadmat`.\n",
    "\n",
    "- **load_mat_any_version(mat_path):**\n",
    "  - Checks if a v7.2-converted file already exists and loads it if available.\n",
    "  - Otherwise, tries to load the original file with `scipy.io.loadmat`.\n",
    "  - If the file is v7.3 and not supported, it converts it to v7.2 and then loads the converted file.\n",
    "\n",
    "- **Usage:**\n",
    "  - Specify the path to your `.mat` file (`mat_path`).\n",
    "  - Call `load_mat_any_version(mat_path)` to load the data, regardless of the MATLAB version.\n",
    "  - The loaded data is a Python dictionary with keys corresponding to the variables in the `.mat` file.\n",
    "\n",
    "### Benefits\n",
    "\n",
    "- **Automatic compatibility:** Handles both old and new MATLAB formats seamlessly.\n",
    "- **Caching:** Avoids repeated conversion by saving and reusing the v7.2 file.\n",
    "- **No manual intervention:** Just use `load_mat_any_version` for any `.mat` file.\n",
    "\n",
    "---\n",
    "\n",
    "**Example output:**\n",
    "```\n",
    "Loaded keys: dict_keys(['Houston13', '__header__', '__version__', '__globals__'])\n",
    "```\n",
    "This shows the variable names loaded from the `.mat` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import loadmat, savemat\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def convert_mat_v73_to_v72(v73_path, v72_path):\n",
    "    def extract_group(g):\n",
    "        d = {}\n",
    "        for k, v in g.items():\n",
    "            if isinstance(v, h5py.Dataset):\n",
    "                d[k] = v[()]\n",
    "            elif isinstance(v, h5py.Group):\n",
    "                d[k] = extract_group(v)\n",
    "        return d\n",
    "    with h5py.File(v73_path, \"r\") as f:\n",
    "        data_dict = extract_group(f)\n",
    "    savemat(v72_path, data_dict)\n",
    "\n",
    "def load_mat_any_version(mat_path):\n",
    "    v72_path = os.path.splitext(mat_path)[0] + \"_v72.mat\"\n",
    "    # 1. If v72 exists, use it\n",
    "    if os.path.exists(v72_path):\n",
    "        print(f\"v7.2 .mat file already exists Found cached : {v72_path}\")\n",
    "        return loadmat(v72_path)\n",
    "    # 2. Otherwise, try to load original\n",
    "    try:\n",
    "        print(f\"Trying to load {mat_path} using scipy.io.loadmat ...\")\n",
    "        return loadmat(mat_path)\n",
    "    except NotImplementedError as e:\n",
    "        if \"Please use HDF reader for matlab v7.3 files\" in str(e):\n",
    "            print(\"File is v7.3 (HDF5). Converting to v7.2 format...\")\n",
    "            convert_mat_v73_to_v72(mat_path, v72_path)\n",
    "            print(f\"Converted to: {v72_path}. Reloading...\")\n",
    "            return loadmat(v72_path)\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v7.2 .mat file already exists Found cached : /home/fesih/Desktop/ubuntu_projects/GAST2/src/Dataset/Houston18/Houston18_v72.mat\n",
      "Loaded keys: dict_keys(['__header__', '__version__', '__globals__', 'ori_data'])\n",
      "Max value in data['ori_data']: 1.0\n",
      "Max value in data['ori_data']: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mat_path =  PROJECT_ROOT / \"src/Dataset/Houston18/Houston18.mat\"\n",
    "\n",
    "data = load_mat_any_version(mat_path)\n",
    "print(\"Loaded keys:\", data.keys())\n",
    "\n",
    "max_value = np.max(data['ori_data'])\n",
    "print(\"Max value in data['ori_data']:\", max_value)\n",
    "\n",
    "max_value = np.min(data['ori_data'])\n",
    "print(\"Max value in data['ori_data']:\", max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v7.2 .mat file already exists Found cached : /home/fesih/Desktop/ubuntu_projects/GAST2/src/Dataset/Houston18/Houston18_7gt_v72.mat\n",
      "Loaded keys: dict_keys(['__header__', '__version__', '__globals__', 'map'])\n",
      "Max value in data['map']: 7.0\n",
      "Max value in data['map']: 0.0\n"
     ]
    }
   ],
   "source": [
    "gt_path =  PROJECT_ROOT / \"src/Dataset/Houston18/Houston18_7gt.mat\"\n",
    "\n",
    "data = load_mat_any_version(gt_path)\n",
    "print(\"Loaded keys:\", data.keys())\n",
    "\n",
    "max_value = np.max(data['map'])\n",
    "print(\"Max value in data['map']:\", max_value)\n",
    "\n",
    "max_value = np.min(data['map'])\n",
    "print(\"Max value in data['map']:\", max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v7.2 .mat file already exists Found cached : /home/fesih/Desktop/ubuntu_projects/GAST2/src/Dataset/Houston13/Houston13_v72.mat\n",
      "Loaded keys: dict_keys(['__header__', '__version__', '__globals__', 'ori_data'])\n",
      "Max value in data['ori_data']: 1.0\n",
      "Max value in data['ori_data']: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mat_path =  PROJECT_ROOT / \"src/Dataset/Houston13/Houston13.mat\"\n",
    "\n",
    "data = load_mat_any_version(mat_path)\n",
    "print(\"Loaded keys:\", data.keys())\n",
    "\n",
    "max_value = np.max(data['ori_data'])\n",
    "print(\"Max value in data['ori_data']:\", max_value)\n",
    "\n",
    "max_value = np.min(data['ori_data'])\n",
    "print(\"Max value in data['ori_data']:\", max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load /home/fesih/Desktop/ubuntu_projects/GAST2/src/Dataset/Houston13/Houston13.mat using scipy.io.loadmat ...\n",
      "Loaded keys: dict_keys(['__header__', '__version__', '__globals__', 'ans'])\n",
      "Max value in data['map']: 65517\n",
      "Max value in data['map']: 0\n"
     ]
    }
   ],
   "source": [
    "gt_path = PROJECT_ROOT / \"src/Dataset/Houston13/Houston13.mat\"\n",
    "\n",
    "data = load_mat_any_version(gt_path)\n",
    "print(\"Loaded keys:\", data.keys())\n",
    "\n",
    "# Now, inspect the keys and use the correct one\n",
    "# For example, if you see 'map' in the keys, you can access data['map']\n",
    "# Otherwise, use one of the keys printed above\n",
    "\n",
    "max_value = np.max(data[list(data.keys())[-1]])\n",
    "print(\"Max value in data['map']:\", max_value)\n",
    "\n",
    "max_value = np.min(data[list(data.keys())[-1]])\n",
    "print(\"Max value in data['map']:\", max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load /home/fesih/Desktop/ubuntu_projects/GAST2/src/Dataset/Houston13/Houston13_gt.mat using scipy.io.loadmat ...\n",
      "Loaded keys: dict_keys(['__header__', '__version__', '__globals__', 'name'])\n",
      "Max value in data['map']: 15\n",
      "Max value in data['map']: 0\n"
     ]
    }
   ],
   "source": [
    "gt_path = PROJECT_ROOT / \"src/Dataset/Houston13/Houston13_gt.mat\"\n",
    "\n",
    "data = load_mat_any_version(gt_path)\n",
    "print(\"Loaded keys:\", data.keys())\n",
    "\n",
    "# Now, inspect the keys and use the correct one\n",
    "# For example, if you see 'map' in the keys, you can access data['map']\n",
    "# Otherwise, use one of the keys printed above\n",
    "\n",
    "max_value = np.max(data[list(data.keys())[-1]])\n",
    "print(\"Max value in data['map']:\", max_value)\n",
    "\n",
    "max_value = np.min(data[list(data.keys())[-1]])\n",
    "print(\"Max value in data['map']:\", max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
